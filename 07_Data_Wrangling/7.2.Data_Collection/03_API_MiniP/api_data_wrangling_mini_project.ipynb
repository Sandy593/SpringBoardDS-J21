{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will require you to pull some data from the Qunadl API. Qaundl is currently the most widely used aggregator of financial market data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, you will need to register a free account on the http://www.quandl.com website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you register, you will be provided with a unique API key, that you should store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the API key as a string - according to PEP8, constants are always named in all upper case\n",
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qaundl has a large number of data sources, but, unfortunately, most of them require a Premium subscription. Still, there are also a good number of free datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this mini project, we will focus on equities data from the Frankfurt Stock Exhange (FSE), which is available for free. We'll try and analyze the stock prices of a company called Carl Zeiss Meditec, which manufactures tools for eye examinations, as well as medical lasers for laser eye surgery: https://www.zeiss.com/meditec/int/home.html. The company is listed under the stock ticker AFX_X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the detailed Quandl API instructions here: https://docs.quandl.com/docs/time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a dedicated Python package for connecting to the Quandl API, we would prefer that you use the *requests* package, which can be easily downloaded using *pip* or *conda*. You can find the documentation for the package here: http://docs.python-requests.org/en/master/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, apart from the *requests* package, you are encouraged to not use any third party Python packages, such as *pandas*, and instead focus on what's available in the Python Standard Library (the *collections* module might come in handy: https://pymotw.com/3/collections/ ).\n",
    "Also, since you won't have access to DataFrames, you are encouraged to us Python's native data structures - preferably dictionaries, though some questions can also be answered using lists.\n",
    "You can read more on these data structures here: https://docs.python.org/3/tutorial/datastructures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the JSON responses you will be getting from the API map almost one-to-one to Python's dictionaries. Unfortunately, they can be very nested, so make sure you read up on indexing dictionaries in the documentation provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the relevant modules\n",
    "import requests\n",
    "import collections\n",
    "from collections import Counter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file using pythons open() function in 'r' mode\n",
    "file = open('test_url.txt', 'r')\n",
    "\n",
    "# Call the method read() on file and assign it to test_url\n",
    "test_url = file.read()\n",
    "\n",
    "# Close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, call the Quandl API and pull out a small sample of the data (only one day) to get a glimpse\n",
    "# into the JSON structure that will be returned\n",
    "\n",
    "# url - 'https://www.quandl.com/api/v3/datasets/fse/afx_x/data.json?api_key=X&start_date=2020-12-01&end_date=2020-12-02'\n",
    "\n",
    "# Using requests.get() to get the response for the request sent\n",
    "rs = requests.get(test_url)\n",
    "\n",
    "# Convert json data to a DataFrame\n",
    "json_data = rs.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_data : {'limit': None, 'transform': None, 'column_index': None, 'column_names': ['Date', 'Open', 'High', 'Low', 'Close', 'Change', 'Traded Volume', 'Turnover', 'Last Price of the Day', 'Daily Traded Units', 'Daily Turnover'], 'start_date': '2020-12-01', 'end_date': '2020-12-01', 'frequency': 'daily', 'data': [['2020-12-01', 112.2, 112.2, 111.5, 112.0, None, 51.0, 5703.0, None, None, None]], 'collapse': None, 'order': None}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the JSON structure of the object you created, and take note of how nested it is,\n",
    "# as well as the overall structure\n",
    "\n",
    "# print the key-value pairs for json_data\n",
    "for k in json_data.keys():\n",
    "    print(k, ':', json_data[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are your tasks for this mini project:\n",
    "\n",
    "1. Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file using pythons open() function in 'r' mode\n",
    "file = open('url.txt', 'r')\n",
    "\n",
    "# Call the method read() on file and assign it to url\n",
    "url = file.read()\n",
    "\n",
    "# Close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using requests.get() to get the response for the request sent\n",
    "\n",
    "#url - https://www.quandl.com/api/v3/datasets/fse/afx_x/data.json?api_key=X&start_date=2017-01-01&end_date=2017-12-31\n",
    "# Using requests.get() to get the response for the request sent\n",
    "rs = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert the returned JSON object into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit\n",
      "transform\n",
      "column_index\n",
      "column_names\n",
      "start_date\n",
      "end_date\n",
      "frequency\n",
      "data\n",
      "collapse\n",
      "order\n"
     ]
    }
   ],
   "source": [
    "# Convert json data to a DataFrame\n",
    "json_data = rs.json()\n",
    "\n",
    "# print the keys for json_data\n",
    "for key,value in json_data.items():\n",
    "    for key1, value1 in value.items():\n",
    "        print(key1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Open', 'High', 'Low', 'Close', 'Change', 'Traded Volume', 'Turnover', 'Last Price of the Day', 'Daily Traded Units', 'Daily Turnover']\n"
     ]
    }
   ],
   "source": [
    "# Print values for the 'column_names' key\n",
    "print(json_data['dataset_data']['column_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2017-12-29', 51.76, 51.94, 51.45, 51.76, None, 34640.0, 1792304.0, None, None, None], ['2017-12-28', 51.65, 51.82, 51.43, 51.6, None, 40660.0, 2099024.0, None, None, None], ['2017-12-27', 51.45, 51.89, 50.76, 51.82, None, 57452.0, 2957018.0, None, None, None], ['2017-12-22', 51.05, 51.5, 50.92, 51.32, None, 71165.0, 3641949.0, None, None, None], ['2017-12-21', 51.16, 51.52, 50.9, 51.4, None, 120649.0, 6179433.0, None, None, None]]\n"
     ]
    }
   ],
   "source": [
    "# Print valurs for the 'data' key\n",
    "print(json_data['dataset_data']['data'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Calculate what the highest and lowest opening prices were for the stock in this period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the values of 'data' key to a variale data\n",
    "data = json_data['dataset_data']['data']\n",
    "\n",
    "# Extract the second element from data as opening_price\n",
    "opening_price = list(list(zip(*data))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert list to numpy array\n",
    "open_array = np.array(opening_price, dtype=float)\n",
    "\n",
    "# Column Mean\n",
    "open_mean = np.nanmean(open_array)\n",
    "\n",
    "# Get the indices for all nan\n",
    "nans = np.where(np.isnan(open_array))\n",
    "\n",
    "# Replace nans with column mean\n",
    "open_array[nans] = open_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest opening prices for the Frankfurt Stock Exhange for the year 2017 34.0\n"
     ]
    }
   ],
   "source": [
    "# print minimum value of opening_price\n",
    "print('Lowest opening prices for the Frankfurt Stock Exhange for the year 2017', min(open_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest opening prices for the Frankfurt Stock Exhange for the year 2017 53.11\n"
     ]
    }
   ],
   "source": [
    "# print minimum value of opening_price\n",
    "print('Highest opening prices for the Frankfurt Stock Exhange for the year 2017', max(open_array))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "opening_prices = json_data['dataset_data']['data']\n",
    "print('Lowest opening prices for the Frankfurt Stock Exhange for the year 2017', min(opening_prices)[1])\n",
    "print('Highest opening prices for the Frankfurt Stock Exhange for the year 2017', max(opening_prices)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What was the largest change in any one day (based on High and Low price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change in any one day based on High and Low price 2.8100000000000023\n"
     ]
    }
   ],
   "source": [
    "# Extract the third element from data as a set high_4each_day\n",
    "high_4each_day = [item[2] for item in data]\n",
    "\n",
    "# Extract the fourth element from data as a set low_4each_day\n",
    "low_4each_day = [item[3] for item in data]\n",
    "\n",
    "# Create an empty list to calculate difference b/w lists\n",
    "change = [x1 - x2 for (x1, x2) in zip(high_4each_day, low_4each_day)]\n",
    "\n",
    "# Print the largest change in any day based on high and low prices\n",
    "print('The largest change in any one day based on High and Low price', max(change))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What was the largest change between any two days (based on Closing Price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the fifth element from zipped as a list closing_pr\n",
    "closing_pr = [item[4] for item in data]\n",
    "\n",
    "# get the change in closing_price \n",
    "closing_pr_change = [(closing_pr[i] - closing_pr[i-1]) for i in range(len(closing_pr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change between any two days based on Closing Price 15.96\n"
     ]
    }
   ],
   "source": [
    "# Print the largest change between any two days based on Closing Price\n",
    "print('The largest change between any two days based on Closing Price',max(closing_pr_change))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Extract the first element from zipped as a list dt\n",
    "dt = [[datetime.strptime(item[0], '%Y-%m-%d'), item[4]] for item in data]\n",
    "\n",
    "# Extract number of days by substracting datetime objects as below\n",
    "change = [[(dt[i-2][0]-dt[i][0]).days, (dt[i-2][1] - dt[i][1])] for i in range(len(dt))]\n",
    "\n",
    "# Extract the change when days is 2\n",
    "change_in_2days = [change[i] for i in range(len(change)) if change[i][0] == 2]\n",
    "\n",
    "# Extract the second column from list\n",
    "change_in_2days_val = [item[1] for item in change_in_2days]\n",
    "\n",
    "# Print the largest change between any two days based on Closing Price\n",
    "print('The largest change between any two days based on Closing Price',max(change_in_2days_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What was the average daily trading volume during this year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the sixth element from zipped as a list traded_volume\n",
    "traded_volume = [item[6] for item in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average daily trading volume during 2017 89124.33725490196\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average traded volume\n",
    "avg_traded_volume_4each_day = sum(traded_volume)/len(traded_volume)\n",
    "\n",
    "# Print the average daily trading volume\n",
    "print('The average daily trading volume during 2017', avg_traded_volume_4each_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. (Optional) What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of traded_volume\n",
    "n = len(traded_volume)\n",
    "\n",
    "# Sort the traded_value\n",
    "sorted_traded_volume = sorted(traded_volume)\n",
    "\n",
    "# Get the index \n",
    "index = len(sorted_traded_volume) // 2\n",
    "\n",
    "if n%2 == 1:\n",
    "    median_traded_volume = sorted_traded_volume[index]\n",
    "else:\n",
    "    median_traded_volume = (sorted_traded_volume[index] + sorted_traded_volume[index + 1])/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median trading volume during 2017 is 76286.0\n"
     ]
    }
   ],
   "source": [
    "# Print the median trading volume during 2017\n",
    "print('The median trading volume during 2017 is', median_traded_volume)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
